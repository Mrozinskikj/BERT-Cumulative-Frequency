{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from utils import count_letters, print_line, read_inputs, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokeniser:\n",
    "    \"\"\"\n",
    "    A class for encoding and decoding strings into tokens for model input.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    length : int\n",
    "        Expected length of input strings. Defaults to 20.\n",
    "    char_to_id : dict\n",
    "        Dictionary mapping characters to their corresponding token IDs.\n",
    "    id_to_char : dict\n",
    "        Dictionary mapping token IDs to their corresponding characters.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    encode(string: str) -> torch.Tensor\n",
    "        Encodes a string into a tensor of token IDs.\n",
    "    \n",
    "    decode(tokens: torch.Tensor) -> str\n",
    "        Decodes a tensor of token IDs into a string.\n",
    "    \"\"\"\n",
    "    def __init__(self, length: int = 20):\n",
    "        \"\"\"\n",
    "        Initialises the tokeniser, defining the vocabulary.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        length : int, optional\n",
    "            Expected length of input strings. Defaults to 20.\n",
    "        \"\"\"\n",
    "        self.length = length\n",
    "        \n",
    "        vocab = [chr(ord('a') + i) for i in range(0, 26)] + [' '] # vocab of lowerchase chars and space\n",
    "\n",
    "        self.char_to_id = {ch: i for i, ch in enumerate(vocab)} # dictionary of character to token id\n",
    "        self.id_to_char = {i: ch for i, ch in enumerate(vocab)} # dictionary of token id to character\n",
    "    \n",
    "    def encode(self, string: str) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Encodes a string into a tensor of token IDs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        string : str\n",
    "            The input string to encode.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (shape [self.length])\n",
    "            A tensor containing the token IDs corresponding to input string.\n",
    "            \n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If 'string' is not 'self.length' characters long.\n",
    "            If 'string' contains out-of-vocabulary characters.\n",
    "        \"\"\"\n",
    "        if len(string) != self.length: # ensure input string is correct length\n",
    "            raise ValueError(f\"Input string must be exactly {self.length} characters long, but got {len(string)} characters.\")\n",
    "        \n",
    "        try:\n",
    "            tokens_list = [self.char_to_id[c] for c in string] # convert string to tokens list\n",
    "        except KeyError as e:\n",
    "            raise ValueError(f\"Out of vocabulary character encountered: '{e.args[0]}'\")\n",
    "        \n",
    "        tokens_tensor = torch.tensor(tokens_list, dtype=torch.long) # convert token list into tensor\n",
    "        return tokens_tensor\n",
    "    \n",
    "    def decode(self, tokens: torch.Tensor) -> str:\n",
    "        \"\"\"\n",
    "        Decodes a tensor of token IDs into a string.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tokens : torch.Tensor\n",
    "            A tensor containing token IDs to decode.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            A decoded string corresponding to input tokens.\n",
    "        \"\"\"\n",
    "        return \"\".join([self.id_to_char[i.item()] for i in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tensor(tensor_list, batch_size) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Converts a list of 1D tensors into a batched 3D tensor. Used with 'process_dataset'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensor_list : list of torch.Tensor\n",
    "        A list of 1D tensors to be batched together.\n",
    "    batch_size : int\n",
    "        The number of tensors to include in each batch.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor (shape [num_batches, batch_size, tensor_length])\n",
    "        A 3D batched tensor, grouping each input tensor into groups of size 'batch_size'.\n",
    "    \"\"\"\n",
    "    tensor_stacked = torch.stack(tensor_list) # convert list of 1D tensors to stacked 2D tensor\n",
    "    \n",
    "    num_batches = len(tensor_stacked) // batch_size # find whole number of batches (may trim last items)\n",
    "    excess_items = len(tensor_stacked) % batch_size # calculate number of extra items which don't fit into batches\n",
    "    if excess_items != 0:\n",
    "        print(f\"Trimming last {excess_items} items to ensure equal batch sizes.\")\n",
    "        tensor_stacked = tensor_stacked[:-excess_items] # trim tensor\n",
    "    \n",
    "    batched_tensor = tensor_stacked.view(num_batches, batch_size, -1) # reshape 2D tensor into batched 3D tensor\n",
    "    return batched_tensor\n",
    "    \n",
    "\n",
    "def process_dataset(inputs, tokeniser, batch_size = 4) -> dict:\n",
    "    \"\"\"\n",
    "    Processes raw data into input tokens and labels, creating a dataset dictionary of batched tensors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inputs : list of str\n",
    "        Train or test data examples split into a list.\n",
    "    tokeniser : Tokeniser\n",
    "        An instance of the Tokeniser class used to encode the input.\n",
    "    batch_size : int, optional\n",
    "        The number of items to include in each batch. Defaults to 4.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        - 'input_ids' : torch.Tensor (shape [num_batches, batch_size, tensor_length])\n",
    "            The batched tensor of tokenised input strings.\n",
    "        - 'labels' : torch.Tensor (shape [num_batches, batch_size, tensor_length])\n",
    "            The batched tensor of labels corresponding to input IDs.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If length of 'inputs' is less than 'batch_size'.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(inputs) < batch_size:\n",
    "        raise ValueError(\"Input list is too short for a single batch.\")\n",
    "\n",
    "    random.shuffle(inputs) # shuffle incase inputs are ordered\n",
    "    input_ids_list = [tokeniser.encode(text) for text in inputs] # list of token tensors for each input\n",
    "    labels_list = [count_letters(text) for text in inputs] # list of label tensors for each input\n",
    "\n",
    "    # create dictionary of batched 3D input and label tensors\n",
    "    dataset = {\n",
    "        'input_ids': batch_tensor(input_ids_list, batch_size),\n",
    "        'labels': batch_tensor(labels_list, batch_size)\n",
    "    }\n",
    "    print(\"Dataset created.\", \", \".join([f\"{key}: {tensor.size()}\" for key, tensor in dataset.items()]))\n",
    "    print_line()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    A class for a BERT Embedding layer which creates and combines token and position embeddings.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    length : int\n",
    "        Expected length of input strings. Defaults to 20.\n",
    "    token_embedding : nn.Embedding\n",
    "        Embedding layer which maps each token to a dense vector of size 'embed_dim'.\n",
    "    position_embedding : nn.Embedding\n",
    "        Embedding layer which maps each position index to a dense vector of size 'embed_dim'.\n",
    "    dropout : nn.Dropout\n",
    "        Dropout layer for regularisation.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(input_ids: torch.Tensor) -> torch.Tensor\n",
    "        Performs a forward pass, computing the BERT embeddings used as model input for a given 'input_ids'.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        dropout: float,\n",
    "        vocab_size: int,\n",
    "        length: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialises the BERT Embedding.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        vocab_size : int\n",
    "            Total number of unique tokens.\n",
    "        length : int\n",
    "            Expected length of input strings.\n",
    "        embed_dim : int\n",
    "            Dimensionality of the token and position embeddings.\n",
    "        dropout : float\n",
    "            Dropout probability, used for regularisation.\n",
    "        \"\"\"\n",
    "        super().__init__() # initialise the nn.Module parent class\n",
    "        self.length = length # store the sequence length\n",
    "\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_dim) # map each token to a dense vector of size embed_dim\n",
    "        self.position_embedding = nn.Embedding(length, embed_dim) # map each position index to a dense vector of size embed_dim\n",
    "        self.dropout = nn.Dropout(dropout) # dropout layer for regularisation\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs a forward pass, computing the BERT embeddings used as model input for a given 'input_ids'.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_ids : torch.Tensor (shape [batch_size, length])\n",
    "            The tensor containing token indices for the input sequences of a given batch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor  (shape [batch_size, length, embed_dim])\n",
    "            The tensor containing the BERT embeddings for the input sequences of a given batch.\n",
    "        \"\"\"\n",
    "        device = input_ids.device # used to ensure all tensors are on same device\n",
    "\n",
    "        token_embedding = self.token_embedding(input_ids) # look up token embeddings for each token in input_ids\n",
    "\n",
    "        position_input = torch.arange(self.length, device=device).unsqueeze(0) # create position indices for each token\n",
    "        position_embedding = self.position_embedding(position_input) # look up position embeddings for each position index in input_ids\n",
    "        \n",
    "        embedding = token_embedding + position_embedding # BERT embedding is element-wise sum of token embeddings and position embeddings\n",
    "        embedding = self.dropout(embedding) # apply dropout for regularisation\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    A class for Layer Normalisation, used to normalise input tensors such that the embedding dimension (-1) has zero mean and unit variance.\n",
    "    Learnable gain and bias parameters for each embedding element allow for increased flexibility for downstream tasks.\n",
    "    Helps to stabilise learning by keeping weights within a controlled range.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    epsilon : float\n",
    "        Small constant preventing division by zero.\n",
    "    gain : nn.Parameter\n",
    "        Learnable gain (multiplier) parameters for each element in embedding dimension. Applied after normalisation.\n",
    "    bias : nn.Parameter\n",
    "        Learnable bias (addition) parameters for each element in embedding dimension. Applied after normalisation.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(input_ids: torch.Tensor) -> torch.Tensor\n",
    "        Normalises and scales the embedding dimension of the input tensor.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        epsilon: float = 1e-5\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialises the LayerNorm module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        embed_dim : int\n",
    "            The size of the embedding dimension. Used to correctly initialise gain and bias parameters.\n",
    "        epsilon : float, optional\n",
    "            Small constant preventing division by zero. Defaults to 1e-5.\n",
    "        \"\"\"\n",
    "        super().__init__() # initialise the nn.Module parent class\n",
    "        self.epsilon = epsilon # small constant prevents division by zero\n",
    "        self.gain = nn.Parameter(torch.ones(embed_dim)) # learnable gain (multiplier) parameters for each element in embed_dim\n",
    "        self.bias = nn.Parameter(torch.zeros(embed_dim)) # learnable bias (addition) parameters for each element in embed_dim\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        inputs: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Normalises and scales the embedding dimension of the input tensor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : torch.Tensor (shape [batch_size, length, embed_dim])\n",
    "            The input tensor to be normalised across 'embed_dim'.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (shape [batch_size, length, embed_dim])\n",
    "            The normalised and scaled input tensor. Prior to scaling, 'embed_dim' has zero mean and unit variance.\n",
    "        \"\"\"\n",
    "        mean = inputs.mean(dim=-1, keepdim=True) # compute the mean across the embedding dimension (-1)\n",
    "        variance = inputs.var(dim=-1, keepdim=True, unbiased=True) # compute the unbiased variance (average of squared deviations from mean) across the embedding dimension (-1)\n",
    "        std = torch.sqrt(variance + self.epsilon) # calculate standard deviation\n",
    "\n",
    "        normalised = (inputs - mean) / std # normalise inputs to mean 0 and standard deviation 1 (unbiased variance means std=1)\n",
    "        scaled = normalised * self.gain + self.bias # normalised tensor is shifted and scaled by learnable parameters. increased flexibility\n",
    "        \n",
    "        return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000]], grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def test_layer_norm():\n",
    "    \"\"\"Tests that LayerNorm forward pass works and returns a tensor of correct shape, and that output mean and standard deviation are close to 0 and 1 respectively.\"\"\"\n",
    "    torch.manual_seed(0)\n",
    "    batch_size, length, embed_dim = 2, 4, 8\n",
    "    input_tensor = torch.randn(batch_size, length, embed_dim)\n",
    "    layer_norm = LayerNorm(embed_dim)\n",
    "    output_tensor = layer_norm(input_tensor)\n",
    "    print(output_tensor.std(dim=-1))\n",
    "\n",
    "    assert output_tensor.size() == input_tensor.size(), f\"Expected shape ({batch_size}, {length}, {embed_dim}), but got {output_tensor['input_ids'].shape}\"\n",
    "    assert torch.allclose(output_tensor.mean(dim=-1), torch.zeros(batch_size, length), atol=1e-4), \"Mean should be close to 0\"\n",
    "    assert torch.allclose(output_tensor.std(dim=-1), torch.ones(batch_size, length), atol=1e-4), \"Std should be close to 1\"\n",
    "\n",
    "test_layer_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A class for an individual attention head within a MultiHeadAttention module.\n",
    "    Projects input embeddings into keys, values, and queries, then computes attention scores.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    head_size : int\n",
    "        Dimension of each of key, value, and query. Calculated by MultiHeadAttention module based on embed_dim and num_heads.\n",
    "    key : nn.Linear\n",
    "        Linear transformation for projecting input tensor into key space.\n",
    "    query : nn.Linear\n",
    "        Linear transformation for projecting input tensor into query space.\n",
    "    value : nn.Linear\n",
    "        Linear transformation for projecting input tensor into value space.\n",
    "    dropout : nn.Dropout\n",
    "        Dropout layer for regularisation.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(input_tensor: torch.Tensor) -> torch.Tensor\n",
    "        Performs a forward pass, computing the attention scores.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        head_size: int,\n",
    "        dropout: float\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialises the AttentionHead module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        embed_dim : int\n",
    "            The size of the embedding dimension.\n",
    "        head_size : int\n",
    "            Dimension of each of key, value, and query. Calculated by MultiHeadAttention module based on embed_dim and num_heads.\n",
    "        dropout : float\n",
    "            Dropout probability, used for regularisation.\n",
    "        \"\"\"\n",
    "        super().__init__() # initialise the nn.Module parent class\n",
    "\n",
    "        self.head_size = head_size\n",
    "\n",
    "        # keys queries and values are projected from embedding dimension to 'head_size'\n",
    "        self.key = nn.Linear(embed_dim, head_size, bias=False)\n",
    "        self.query = nn.Linear(embed_dim, head_size, bias=False)\n",
    "        self.value = nn.Linear(embed_dim, head_size, bias=False)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout) # dropout for regularisation\n",
    "    \n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_tensor: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs a forward pass, computing the attention scores.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_tensor : torch.Tensor (shape [batch_size, length, embed_dim])\n",
    "            The transformer input tensor for which attention needs to be calculated.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (shape [batch_size, length, head_size])\n",
    "            The attention scores.\n",
    "        \"\"\"\n",
    "        # project input tensor to 'head_size' for keys, queries, and values ([batch_size, length, embed_dim] -> [batch_size, length, head_size])\n",
    "        key = self.key(input_tensor)\n",
    "        query = self.query(input_tensor)\n",
    "        value = self.value(input_tensor)\n",
    "\n",
    "        scores = torch.matmul(query, key.transpose(-2,-1)) # attention scores are dot product between query and key ([batch_size, length, head_size] x [batch_size, head_size, length ] -> [batch_size, length, length])\n",
    "        scores = scores / (self.head_size**0.5) # divide by sqrt of head size to normalise to unit variance. increases stability- high variance would make softmax sharp\n",
    "\n",
    "        attn_weights = nn.functional.softmax(scores, dim=-1) # convert scores into probability distribution\n",
    "        attn_weights = self.dropout(attn_weights) # apply dropout for regularisation\n",
    "\n",
    "        output = torch.matmul(attn_weights, value) # output is the weighted sum of values\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A class for processing an input tensor with multiple attention heads in parallel.\n",
    "    Attention head output is recombined with a linear transformation.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    num_heads : int\n",
    "        Number of attention heads. Must be a factor of 'embed_dim'.\n",
    "    heads : nn.ModuleList\n",
    "        List containing all 'num_heads' intances of 'AttentionHead'.\n",
    "    linear : nn.Linear\n",
    "        Linear transformation to re-integrate attenion head outputs into a unified representation.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(input_tensor: torch.Tensor) -> torch.Tensor\n",
    "        Performs a forward pass, processing the input_tensor through multiple attention heads.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        num_heads: int,\n",
    "        dropout: float\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialises the MultiHeadAttention module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        embed_dim : int\n",
    "            The size of the embedding dimension.\n",
    "        num_heads : int\n",
    "            Number of attention heads. Must be a factor of 'embed_dim'.\n",
    "        dropout : float\n",
    "            Dropout probability, used for regularisation.\n",
    "        \"\"\"\n",
    "        super().__init__() # initialise the nn.Module parent class\n",
    "\n",
    "        if embed_dim % num_heads != 0: # ensure each attention head gets an equal distribution of the input tensor\n",
    "            raise ValueError(\"embed_dim must be divisible by num_heads.\")\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        head_size = embed_dim // num_heads # size of each attention head is such that the concatenation of all attention heads is embed_dim\n",
    "\n",
    "        self.heads = nn.ModuleList([\n",
    "            AttentionHead(embed_dim, head_size, dropout) for _ in range(num_heads)\n",
    "        ]) # list of all attention heads\n",
    "\n",
    "        self.linear = nn.Linear(embed_dim, embed_dim) # linear transformation\n",
    "    \n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs a forward pass, processing the input_tensor through multiple attention heads.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_tensor : torch.Tensor (shape [batch_size, length, embed_dim])\n",
    "            The input tensor to be processed by the attention mechanism.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (shape [batch_size, length, embed_dim])\n",
    "            The final output tensor after attention computation and reintegration.\n",
    "        \"\"\"\n",
    "        head_outputs = [head(input_tensor) for head in self.heads] # compute the attention scores of each head in parallel\n",
    "        concatenated = torch.cat(head_outputs, dim=-1) # concatenate all attention head outputs back into single tensor\n",
    "        output = self.linear(concatenated) # re-integrate attention heads into unified representation with final linear transformation\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    A class for a single Transformer layer composed of multi-head attention, normalisation, and feed-forward layers.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    attention : MultiHeadAttention\n",
    "        Attention mechanism capturing the relationships between each item in the input sequence.\n",
    "    layer_norm1 : LayerNorm\n",
    "        Normalisation of the attention sub-layer, for stability.\n",
    "    feedforward : nn.Sequential\n",
    "        Two layer deep feed-forward network to process the attention sub-layer. Uses GELU activation as per BERT paper.\n",
    "    layer_norm2 : LayerNorm\n",
    "        Normalisation of the feed-forward sub-layer, for stability.\n",
    "    dropout : nn.Dropout\n",
    "        Dropout layer for regularisation.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(input_ids: torch.Tensor) -> torch.Tensor\n",
    "        Performs a forward pass, computing the intermediate transformer output representation.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        attention_heads: int,\n",
    "        dropout: float\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialises the BERT Model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        embed_dim : int\n",
    "            Dimensionality of the embeddings.\n",
    "        dropout : float\n",
    "            Dropout probability, used for regularisation.\n",
    "        attention_heads : int\n",
    "            The number of attention heads in the Transformer encoder layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention = MultiHeadAttention(embed_dim, attention_heads, dropout) # attention mechanism capturing relationships between each item in input\n",
    "        self.layer_norm1 = LayerNorm(embed_dim) # normalisation for stability\n",
    "        \n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim * 4, embed_dim)\n",
    "        ) # 2 layer deep feed-forward network\n",
    "        self.layer_norm2 = LayerNorm(embed_dim) # normalisation for stability\n",
    "        self.dropout = nn.Dropout(dropout) # dropout for regularisation\n",
    "    \n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_tensor: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs a forward pass, computing the intermediate transformer output representation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_tensor : torch.Tensor (shape [batch_size, length, embed_dim])\n",
    "            The transformer input tensor.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (shape [batch_size, length, embed_dim])\n",
    "            The transformer output tensor.\n",
    "        \"\"\"\n",
    "        attn_output = self.attention(input_tensor) # compute the attention scores\n",
    "        attn_output = input_tensor + self.dropout(attn_output) # residual connection and dropout\n",
    "        attn_output = self.layer_norm1(attn_output) # layer normalisation\n",
    "\n",
    "        ffwd_output = self.feedforward(attn_output) # process through feed-forward network\n",
    "        ffwd_output = attn_output + self.dropout(ffwd_output) # residual connection and dropout\n",
    "        output_tensor = self.layer_norm2(ffwd_output) # layer normalisation\n",
    "        \n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    \"\"\"\n",
    "    A class for a BERT model, used to classify the cumulative frequencies of the respective character of every 'input_ids' item.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    embedding : BERTEmbedding\n",
    "        Embedding layer which combines token and position embeddings.\n",
    "    transformer_layers : nn.ModuleList\n",
    "        A list of TransformerLayer modules. Input is fed through each layer in sequence.\n",
    "    classifier : nn.Linear\n",
    "        Output layer, predicting classes 0, 1, 2 for cumulative character frequency for each position in sequence\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(input_ids: torch.Tensor) -> torch.Tensor\n",
    "        Performs a forward pass, computing the logits for each class of each item of 'input_ids'.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        dropout: float,\n",
    "        attention_heads: int,\n",
    "        layers: int,\n",
    "        vocab_size: int = 27,\n",
    "        length: int = 20,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialises the BERT Model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        embed_dim : int\n",
    "            Dimensionality of the token and position embeddings.\n",
    "        dropout : float\n",
    "            Dropout probability, used for regularisation.\n",
    "        attention_heads : int\n",
    "            The number of attention heads in the Transformer encoder layer.\n",
    "        layers : int\n",
    "            The number of Transformer encoder layers.\n",
    "        vocab_size : int, optional\n",
    "            Total number of unique tokens. Defaults to 27.\n",
    "        length : int, optional\n",
    "            Expected length of input strings. Defaults to 20.\n",
    "        \"\"\"\n",
    "        super().__init__() # initialise the nn.Module parent class\n",
    "        \n",
    "        self.embedding = BERTEmbedding(embed_dim, dropout, vocab_size, length) # embedding layer which combines token and position embeddings\n",
    "        \n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            TransformerLayer(embed_dim, attention_heads, dropout) for _ in range(layers)\n",
    "        ]) # sequence of transformer layers\n",
    "\n",
    "        self.classifier = nn.Linear(embed_dim, 3) # output layer, predicting classes 0, 1, 2 for each position in sequence\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs a forward pass, computing the logits for each class of each item of 'input_ids'.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_ids : torch.Tensor (shape [batch_size, length])\n",
    "            The tensor containing token indices for the input sequences of a given batch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor  (shape [batch_size, length, 3 (classes)])\n",
    "            The tensor containing the class logits for each item of the input sequences of a given batch.\n",
    "        \"\"\"\n",
    "        embeddings = self.embedding(input_ids) # get embeddings for each token in input_ids\n",
    "\n",
    "        for layer in self.transformer_layers: # feed input through each transformer layer in sequence\n",
    "            embeddings = layer(embeddings)\n",
    "\n",
    "        logits = self.classifier(embeddings) # apply classifier to each position to get logits for each class\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'seed': 0,\n",
    "    'batch_size': 4,\n",
    "    'learning_rate': 1e-6,\n",
    "    'epochs': 1,\n",
    "    'warmup_ratio': 0.1,\n",
    "    'eval_every': 250,\n",
    "    'embed_dim': 768,\n",
    "    'dropout': 0.1,\n",
    "    'attention_heads': 12,\n",
    "    'layers': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT(\n",
      "  (embedding): BERTEmbedding(\n",
      "    (token_embedding): Embedding(27, 768)\n",
      "    (position_embedding): Embedding(20, 768)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_layers): ModuleList(\n",
      "    (0-1): 2 x TransformerLayer(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-11): 12 x AttentionHead(\n",
      "            (key): Linear(in_features=768, out_features=64, bias=False)\n",
      "            (query): Linear(in_features=768, out_features=64, bias=False)\n",
      "            (value): Linear(in_features=768, out_features=64, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (layer_norm1): LayerNorm()\n",
      "      (feedforward): Sequential(\n",
      "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      )\n",
      "      (layer_norm2): LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BERT(\n",
    "    params['embed_dim'],\n",
    "    params['dropout'],\n",
    "    params['attention_heads'],\n",
    "    params['layers'],\n",
    ") # initialise model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 lines read\n",
      "--------------------------------------------------------------------------------\n",
      "1000 lines read\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset created. input_ids: torch.Size([2500, 4, 20]), labels: torch.Size([2500, 4, 20])\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset created. input_ids: torch.Size([250, 4, 20]), labels: torch.Size([250, 4, 20])\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'seed': 0,\n",
    "    'batch_size': 4,\n",
    "    'learning_rate': 1e-6,\n",
    "    'epochs': 1,\n",
    "    'warmup_ratio': 0.1,\n",
    "    'eval_every': 250,\n",
    "    'embed_dim': 768,\n",
    "    'dropout': 0.1,\n",
    "    'attention_heads': 12,\n",
    "    'layers': 2\n",
    "}\n",
    "model = BERT(\n",
    "    params['embed_dim'],\n",
    "    params['dropout'],\n",
    "    params['attention_heads'],\n",
    "    params['layers'],\n",
    ") # initialise model\n",
    "tokeniser = Tokeniser()\n",
    "train_inputs = read_inputs(\"../../data/train.txt\")\n",
    "test_inputs = read_inputs(\"../../data/test.txt\")\n",
    "dataset_train = process_dataset(train_inputs, tokeniser)\n",
    "dataset_test = process_dataset(test_inputs, tokeniser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.Tensor([[[0.2,0.1,0.3],[0.5,0.1,0.1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dataset_test['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "\n",
    "def lr_scheduler(\n",
    "    warmup_ratio: float,\n",
    "    step_current: int,\n",
    "    step_total: int\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Defines a custom learning rate scheduler (warmup and decay) to adjust learning rate based on current training step.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    warmup_ratio : float\n",
    "        The ratio of total training steps that learning rate warmup occurs for. 0 = no warmup, 1 = all warmup.\n",
    "    step_current : int\n",
    "        The current training step during evaluation.\n",
    "    step_total : int\n",
    "        The total number of training steps.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The ratio that the learning rate will be multiplied by for the given training step.\n",
    "    \"\"\"\n",
    "    warmup_steps = int(step_total*warmup_ratio)\n",
    "    if step_current < warmup_steps: # LR warmup for initial steps\n",
    "        return step_current/max(1,warmup_steps)\n",
    "    else: # linear LR decay for remaining steps\n",
    "        return (step_total-step_current) / max(1,step_total-warmup_steps)\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    model: BERT,\n",
    "    dataset_test: dict,\n",
    "    loss_fn: nn.CrossEntropyLoss,\n",
    "    plot_data: dict,\n",
    "    step_current: int,\n",
    "    step_total: int\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Peforms model evaluation by computing the average loss of the entire test dataset. The average loss is printed and 'plot_data' is updated.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : BERT\n",
    "        An instance of the BERT model to be evaluated.\n",
    "    dataset_test : dict\n",
    "        A dictionary containing the inputs and labels of the test data.\n",
    "        - 'input_ids' : torch.Tensor (shape [num_batches, batch_size, tensor_length])\n",
    "            The batched tensor of tokenised input strings.\n",
    "        - 'labels' : torch.Tensor (shape [num_batches, batch_size, tensor_length])\n",
    "            The batched tensor of labels corresponding to input IDs.\n",
    "    loss_fn : nn.CrossEntropyLoss\n",
    "        The loss function used to compute the loss between the predictions and labels.\n",
    "    plot_data : dict\n",
    "        A dictionary of x and y timeline data of training progress.\n",
    "        - 'train' : dict\n",
    "            Timeline data for the training loss.\n",
    "            - 'x': list\n",
    "                A list of x-coordinate values, representing the given training step.\n",
    "            - 'y': list\n",
    "                A list of y-coordinate values, representing the value at the given training step.\n",
    "        - 'test' : dict\n",
    "            Timeline data for the validation loss.\n",
    "            Refer to 'train'.\n",
    "        - 'lr' : dict\n",
    "            Timeline data for the learning rate.\n",
    "            Refer to 'train'.\n",
    "    step_current : int\n",
    "        The current training step during evaluation.\n",
    "    step_total : int\n",
    "        The total number of training steps.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The updated plot data dictionary with the test loss added.\n",
    "    \"\"\"\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    batches = len(dataset_test['input_ids']) # number of batches in the test dataset\n",
    "    loss_total = 0\n",
    "\n",
    "    with torch.no_grad():  # disable gradient calculation\n",
    "        for batch in range(batches):\n",
    "            \n",
    "            logits = model(dataset_test['input_ids'][batch]) # forward pass to compute logits\n",
    "            logits = logits.view(-1, logits.size(-1)) # flatten batch dimension: [batch_size * length, classes]\n",
    "            labels = dataset_test['labels'][batch].view(-1) # flatten batch dimension: [batch_size * length]\n",
    "\n",
    "            loss_batch = loss_fn(logits, labels) # calculate loss between output logits and labels\n",
    "            loss_total += loss_batch.item()\n",
    "\n",
    "    loss_average = loss_total / batches # loss is the average of all batches\n",
    "    model.train() # revert model to training mode\n",
    "\n",
    "    plot_data['test']['x'].append(step_current)\n",
    "    plot_data['test']['y'].append(loss_average)\n",
    "    print(f'step: {step_current}/{step_total} eval loss: {round(loss_average,2)}')\n",
    "    return plot_data\n",
    "\n",
    "\n",
    "def train_classifier(\n",
    "    model: BERT,\n",
    "    dataset_train: dict,\n",
    "    dataset_test: dict,\n",
    "    learning_rate: float,\n",
    "    epochs: int,\n",
    "    warmup_ratio: float,\n",
    "    eval_every: int,\n",
    "    print_train: bool = False,\n",
    "    plot: bool = True\n",
    ") -> BERT:\n",
    "    \"\"\"\n",
    "    Creates and trains a BERT model for cumulative frequency classification given a training dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : BERT\n",
    "        An instance of the BERT model to perform training on.\n",
    "    dataset_train : dict\n",
    "        A dictionary containing the inputs and labels of the training data.\n",
    "        - 'input_ids' : torch.Tensor (shape [num_batches, batch_size, tensor_length])\n",
    "            The batched tensor of tokenised input strings.\n",
    "        - 'labels' : torch.Tensor (shape [num_batches, batch_size, tensor_length])\n",
    "            The batched tensor of labels corresponding to input IDs.\n",
    "    dataset_train : dict\n",
    "        A dictionary containing the inputs and labels of the test data.\n",
    "        Refer to 'dataset_train'.\n",
    "    learning_rate : float\n",
    "        The learning rate for the optimiser (magnitiude of weight updates per step).\n",
    "    epochs : int\n",
    "        The number of epochs for training. Each epoch corresponds to one full iteration through training data.\n",
    "    warmup_ratio : float\n",
    "        The ratio of total training steps that learning rate warmup occurs for. 0 = no warmup, 1 = all warmup.\n",
    "\n",
    "    print_train : bool, optional\n",
    "        Whether to print the training state at every training step. Defaults to False.\n",
    "    plot : bool, optional\n",
    "        Whether to display a plot of the training timeline once training is finished. Defaults to True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    BERT\n",
    "        The trained BERT model.\n",
    "    \"\"\"\n",
    "    plot_data = {key: {'x':[], 'y':[]} for key in ['train','test','lr']} # dict storing x,y plot data for training progress\n",
    "    \n",
    "    model.train() # set model to training mode\n",
    "\n",
    "    batches = len(dataset_train['input_ids']) # number of batches in the training dataset\n",
    "    step_total = batches*epochs\n",
    "\n",
    "    optimiser = torch.optim.AdamW(model.parameters(), lr=learning_rate) # initialise AdamW optimiser\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimiser, lr_lambda=lambda step: lr_scheduler(warmup_ratio, step, step_total)) # create custom learning rate scheduler\n",
    "    loss_fn = nn.CrossEntropyLoss() # initialise cross-entropy loss function for classification\n",
    "\n",
    "    print(\"Beginning Training.\")\n",
    "    print_line()\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs): # iterate through epochs\n",
    "        for batch in range(batches): # iterate through batches in epoch\n",
    "            step_current = batch*(epoch+1)\n",
    "            \n",
    "            if batch%eval_every == 0: # perform evaluation on test split at set intervals\n",
    "                plot_data = evaluate(model, dataset_test, loss_fn, plot_data, step_current, step_total)\n",
    "\n",
    "            logits = model(dataset_train['input_ids'][batch]) # forward pass to compute logits\n",
    "            logits = logits.view(-1, logits.size(-1)) # flatten batch dimension: [batch_size * length, classes]\n",
    "            labels = dataset_train['labels'][batch].view(-1) # flatten batch dimension: [batch_size * length]\n",
    "            \n",
    "            loss = loss_fn(logits, labels) # calculate loss between output logits and labels\n",
    "            \n",
    "            optimiser.zero_grad() # zero the gradients from previous step (no gradient accumulation)\n",
    "            loss.backward() # backpropagate to compute gradients\n",
    "            optimiser.step() # update model weights\n",
    "            scheduler.step() # update learning rate\n",
    "\n",
    "            plot_data['train']['x'].append(step_current)\n",
    "            plot_data['train']['y'].append(loss.item())\n",
    "            plot_data['lr']['x'].append(step_current)\n",
    "            plot_data['lr']['y'].append(scheduler.get_last_lr()[0])\n",
    "            if print_train:\n",
    "                print(f'step: {step_current}/{step_total} train loss: {round(loss.item(),2)}, LR: {scheduler.get_last_lr()[0]:.2e}')\n",
    "    \n",
    "    if batch%eval_every != 0: # perform final evaluation (as long as not already performed on this step)\n",
    "        plot_data = evaluate(model, dataset_test, loss_fn, plot_data, step_current, step_total)\n",
    "    print(f\"Finishing Training. Time taken: {(time.time()-start_time):.2f} seconds.\")\n",
    "    print_line()\n",
    "    return model, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training.\n",
      "--------------------------------------------------------------------------------\n",
      "step: 0/2500 eval loss: 1.2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwarmup_ratio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval_every\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 179\u001b[0m, in \u001b[0;36mtrain_classifier\u001b[1;34m(model, dataset_train, dataset_test, learning_rate, epochs, warmup_ratio, eval_every, print_train, plot)\u001b[0m\n\u001b[0;32m    177\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# zero the gradients from previous step (no gradient accumulation)\u001b[39;00m\n\u001b[0;32m    178\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# backpropagate to compute gradients\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[43moptimiser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# update model weights\u001b[39;00m\n\u001b[0;32m    180\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# update learning rate\u001b[39;00m\n\u001b[0;32m    182\u001b[0m plot_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(step_current)\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:130\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[0;32m    129\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(opt, opt\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m             )\n\u001b[1;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adamw.py:227\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    217\u001b[0m         group,\n\u001b[0;32m    218\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         state_steps,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 227\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adamw.py:767\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    765\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 767\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adamw.py:434\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    432\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m--> 434\u001b[0m     \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(params[i]):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train_classifier(\n",
    "    model,\n",
    "    dataset_train,\n",
    "    dataset_test,\n",
    "    params['learning_rate'],\n",
    "    params['epochs'],\n",
    "    params['warmup_ratio'],\n",
    "    params['eval_every'],\n",
    "    print_train=False,\n",
    "    plot=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, dataset_test):\n",
    "    predictions_list = [] # list to store every batch of predictions\n",
    "    for batch in dataset_test['input_ids']:\n",
    "        logits = model(batch) # derive the logits of one batch of inputs\n",
    "        prediction = torch.argmax(logits, dim=-1) # prediction is the highest value logit for each item in sequence\n",
    "        predictions_list.append(prediction)\n",
    "    \n",
    "    predictions = torch.stack(predictions_list).view(1000, 20) # convert list to tensor and flatten batch dimension\n",
    "    labels = dataset_test['labels'].view(1000, 20) # flatten batch dimension of labels\n",
    "    \n",
    "    print(f\"Test Accuracy: {100.0 * score(predictions, labels):.2f}%\") # calculate score\n",
    "    print_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
      "     ---------------------------------------- 0.0/107.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 107.8/107.8 kB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\mrozi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-optimize) (24.1)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "     ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 301.8/301.8 kB 9.4 MB/s eta 0:00:00\n",
      "Collecting scikit-learn>=1.0.0\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-win_amd64.whl (11.0 MB)\n",
      "     ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 1.1/11.0 MB 22.4 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 2.9/11.0 MB 30.3 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 3.3/11.0 MB 29.9 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 5.5/11.0 MB 32.1 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 6.8/11.0 MB 29.0 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 8.6/11.0 MB 30.6 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 8.8/11.0 MB 31.2 MB/s eta 0:00:01\n",
      "     --------------------------------------- 11.0/11.0 MB 29.7 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.1.0\n",
      "  Downloading scipy-1.14.1-cp310-cp310-win_amd64.whl (44.8 MB)\n",
      "     ---------------------------------------- 0.0/44.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.6/44.8 MB 19.2 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 1.8/44.8 MB 23.5 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 3.4/44.8 MB 27.1 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 4.8/44.8 MB 27.6 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 6.2/44.8 MB 28.3 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 8.0/44.8 MB 30.1 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 9.1/44.8 MB 30.7 MB/s eta 0:00:02\n",
      "     --------- ----------------------------- 10.6/44.8 MB 31.2 MB/s eta 0:00:02\n",
      "     --------- ----------------------------- 11.3/44.8 MB 29.7 MB/s eta 0:00:02\n",
      "     ---------- ---------------------------- 12.1/44.8 MB 28.4 MB/s eta 0:00:02\n",
      "     ----------- --------------------------- 12.7/44.8 MB 26.2 MB/s eta 0:00:02\n",
      "     ----------- --------------------------- 13.5/44.8 MB 24.2 MB/s eta 0:00:02\n",
      "     ------------ -------------------------- 14.2/44.8 MB 23.4 MB/s eta 0:00:02\n",
      "     ------------- ------------------------- 15.0/44.8 MB 22.6 MB/s eta 0:00:02\n",
      "     ------------- ------------------------- 15.8/44.8 MB 21.1 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 16.6/44.8 MB 21.1 MB/s eta 0:00:02\n",
      "     --------------- ----------------------- 17.3/44.8 MB 19.3 MB/s eta 0:00:02\n",
      "     --------------- ----------------------- 18.1/44.8 MB 18.2 MB/s eta 0:00:02\n",
      "     ---------------- ---------------------- 18.7/44.8 MB 17.7 MB/s eta 0:00:02\n",
      "     ---------------- ---------------------- 19.5/44.8 MB 17.2 MB/s eta 0:00:02\n",
      "     ----------------- --------------------- 20.0/44.8 MB 16.0 MB/s eta 0:00:02\n",
      "     ------------------ -------------------- 20.8/44.8 MB 15.6 MB/s eta 0:00:02\n",
      "     ------------------ -------------------- 21.6/44.8 MB 16.8 MB/s eta 0:00:02\n",
      "     ------------------- ------------------- 22.3/44.8 MB 16.0 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 23.1/44.8 MB 16.4 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 23.9/44.8 MB 16.4 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 24.6/44.8 MB 16.4 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 25.1/44.8 MB 16.0 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 25.7/44.8 MB 15.6 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 26.3/44.8 MB 15.2 MB/s eta 0:00:02\n",
      "     ----------------------- --------------- 26.9/44.8 MB 15.2 MB/s eta 0:00:02\n",
      "     ----------------------- --------------- 27.5/44.8 MB 14.9 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 28.1/44.8 MB 14.6 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 28.5/44.8 MB 14.2 MB/s eta 0:00:02\n",
      "     ------------------------- ------------- 29.0/44.8 MB 13.9 MB/s eta 0:00:02\n",
      "     ------------------------- ------------- 29.5/44.8 MB 13.6 MB/s eta 0:00:02\n",
      "     -------------------------- ------------ 29.9/44.8 MB 13.4 MB/s eta 0:00:02\n",
      "     -------------------------- ------------ 30.4/44.8 MB 13.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------ 30.9/44.8 MB 12.8 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 31.4/44.8 MB 12.6 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 31.9/44.8 MB 12.4 MB/s eta 0:00:02\n",
      "     ---------------------------- ---------- 32.3/44.8 MB 12.1 MB/s eta 0:00:02\n",
      "     ---------------------------- ---------- 32.9/44.8 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------------------- --------- 33.4/44.8 MB 11.7 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 33.8/44.8 MB 11.3 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 34.3/44.8 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 34.8/44.8 MB 10.9 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 35.2/44.8 MB 10.9 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 35.6/44.8 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 36.0/44.8 MB 10.6 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 36.4/44.8 MB 10.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 36.8/44.8 MB 10.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 37.2/44.8 MB 10.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 37.7/44.8 MB 9.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 38.0/44.8 MB 9.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 38.5/44.8 MB 9.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 38.9/44.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 39.3/44.8 MB 9.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 39.7/44.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 40.2/44.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 40.6/44.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 41.0/44.8 MB 9.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 41.5/44.8 MB 9.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 42.0/44.8 MB 9.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 42.4/44.8 MB 9.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 42.9/44.8 MB 9.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 43.4/44.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  43.9/44.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  44.4/44.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  44.8/44.8 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  44.8/44.8 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 44.8/44.8 MB 8.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\mrozi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-optimize) (2.1.1)\n",
      "Collecting pyaml>=16.9\n",
      "  Downloading pyaml-24.7.0-py3-none-any.whl (24 kB)\n",
      "Collecting PyYAML\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "     ---------------------------------------- 0.0/161.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 161.8/161.8 kB 10.1 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, PyYAML, joblib, scikit-learn, pyaml, scikit-optimize\n",
      "Successfully installed PyYAML-6.0.2 joblib-1.4.2 pyaml-24.7.0 scikit-learn-1.5.2 scikit-optimize-0.10.2 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params_list, param_names, dataset_train, dataset_test):\n",
    "    params = {\n",
    "        'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        'seed': 0,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate': 1e-5,\n",
    "        'epochs': 1,\n",
    "        'warmup_ratio': 0.1,\n",
    "        'eval_every': 250,\n",
    "        'embed_dim': 768,\n",
    "        'dropout': 0.1,\n",
    "        'attention_heads': 2,\n",
    "        'layers': 2\n",
    "    }\n",
    "    params_dict = dict(zip(param_names, params_list))\n",
    "    params.update(params_dict)\n",
    "\n",
    "    try:\n",
    "        model = BERT(\n",
    "            embed_dim=params['embed_dim'],\n",
    "            dropout=params['dropout'],\n",
    "            attention_heads=params['attention_heads'],\n",
    "            layers=params['layers']\n",
    "        )\n",
    "        \n",
    "        _, loss = train_classifier(\n",
    "            model=model,\n",
    "            dataset_train=dataset_train,\n",
    "            dataset_test=dataset_test,\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            warmup_ratio=params['warmup_ratio'],\n",
    "            eval_every=params['eval_every'],\n",
    "            print_train=False,\n",
    "            plot=False\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(f\"Invalid parameter combination: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'learning_rate': Real(1e-6, 1e-3, prior='log-uniform'),\n",
    "    'dropout': Real(0.0, 0.5),\n",
    "    'layers': Integer(1, 8)\n",
    "}\n",
    "param_names = list(search_space.keys())\n",
    "dimensions = list(search_space.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_with_data = partial(objective, param_names=param_names, dataset_train=dataset_train, dataset_test=dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgp_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective_with_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skopt\\optimizer\\gp.py:281\u001b[0m, in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     base_estimator \u001b[38;5;241m=\u001b[39m cook_estimator(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGP\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    276\u001b[0m         space\u001b[38;5;241m=\u001b[39mspace,\n\u001b[0;32m    277\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrng\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax),\n\u001b[0;32m    278\u001b[0m         noise\u001b[38;5;241m=\u001b[39mnoise,\n\u001b[0;32m    279\u001b[0m     )\n\u001b[1;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_random_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_random_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_initial_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_point_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_point_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skopt\\optimizer\\base.py:332\u001b[0m, in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_calls):\n\u001b[0;32m    331\u001b[0m     next_x \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mask()\n\u001b[1;32m--> 332\u001b[0m     next_y \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m     result \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mtell(next_x, next_y)\n\u001b[0;32m    334\u001b[0m     result\u001b[38;5;241m.\u001b[39mspecs \u001b[38;5;241m=\u001b[39m specs\n",
      "Cell \u001b[1;32mIn[104], line 26\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(params_list, param_names, dataset_train, dataset_test)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     model \u001b[38;5;241m=\u001b[39m BERT(\n\u001b[0;32m     20\u001b[0m         embed_dim\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membed_dim\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     21\u001b[0m         dropout\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     22\u001b[0m         attention_heads\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_heads\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     23\u001b[0m         layers\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     24\u001b[0m     )\n\u001b[1;32m---> 26\u001b[0m     _, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarmup_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwarmup_ratio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval_every\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprint_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid parameter combination: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[47], line 169\u001b[0m, in \u001b[0;36mtrain_classifier\u001b[1;34m(model, dataset_train, dataset_test, learning_rate, epochs, warmup_ratio, eval_every, print_train, plot)\u001b[0m\n\u001b[0;32m    166\u001b[0m step_current \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m*\u001b[39m(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch\u001b[38;5;241m%\u001b[39meval_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# perform evaluation on test split at set intervals\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_current\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_total\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(dataset_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m][batch]) \u001b[38;5;66;03m# forward pass to compute logits\u001b[39;00m\n\u001b[0;32m    172\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m# flatten batch dimension: [batch_size * length, classes]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[47], line 89\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, dataset_test, loss_fn, plot_data, step_current, step_total)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# disable gradient calculation\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batches):\n\u001b[1;32m---> 89\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# forward pass to compute logits\u001b[39;00m\n\u001b[0;32m     90\u001b[0m         logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m# flatten batch dimension: [batch_size * length, classes]\u001b[39;00m\n\u001b[0;32m     91\u001b[0m         labels \u001b[38;5;241m=\u001b[39m dataset_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m][batch]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# flatten batch dimension: [batch_size * length]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[31], line 77\u001b[0m, in \u001b[0;36mBERT.forward\u001b[1;34m(self, input_ids)\u001b[0m\n\u001b[0;32m     74\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(input_ids) \u001b[38;5;66;03m# get embeddings for each token in input_ids\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_layers: \u001b[38;5;66;03m# feed input through each transformer layer in sequence\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(embeddings) \u001b[38;5;66;03m# apply classifier to each position to get logits for each class\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[30], line 76\u001b[0m, in \u001b[0;36mTransformerLayer.forward\u001b[1;34m(self, input_tensor)\u001b[0m\n\u001b[0;32m     73\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m input_tensor \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attn_output) \u001b[38;5;66;03m# residual connection and dropout\u001b[39;00m\n\u001b[0;32m     74\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm1(attn_output) \u001b[38;5;66;03m# layer normalisation\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m ffwd_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeedforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# process through feed-forward network\u001b[39;00m\n\u001b[0;32m     77\u001b[0m ffwd_output \u001b[38;5;241m=\u001b[39m attn_output \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(ffwd_output) \u001b[38;5;66;03m# residual connection and dropout\u001b[39;00m\n\u001b[0;32m     78\u001b[0m output_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm2(ffwd_output) \u001b[38;5;66;03m# layer normalisation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mrozi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = gp_minimize(\n",
    "    func=objective_with_data,\n",
    "    dimensions=dimensions,\n",
    "    n_calls=20,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.10.2'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skopt.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
